\section{A Better Betting Algorithm for Known $T$ and its Application to the Expert Setting}

In this section we show how it is straightforward to obtain new parameter-free expert algorithms with quantile guarantees.
As seen in the previous section, we need a 1-dimensional algorithm that has an exponential gain, up to negative logarithm terms. In alternative, given the duality between regret and wealth, we can look for 1-dimensional \ac{OLO} algorithms that have a $\scO(|u|\sqrt{T \log(\sqrt{T} |u|)})$ regret.

The \ac{KT} bettor suffers from the problem of having a negative logarithmic term in the exponent of the wealth function, that becomes a $log(T)$ factor in the expert reduction.
To fix it, it would be enough to add such a term in the potential function $f$. When the number of rounds is known beforehand, this can be easily done.

Hence, we present a betting algorithm for the case that the number of rounds $T$ is known. We show that in this case it is possible to have a quantile bound without spurios $\ln T$ or $\ln \ln T$.
We will use the following potential function
\begin{equation}
\label{eq:kt_new_potential}
f\left( x_{t}, \{|z_1|, \ldots, |z_{t}|\}\right) 
= \epsilon  \frac{2^{t} \cdot \Gamma \left(\frac{\delta+t+1}{2} + \frac{1}{2} x_{t} \right) \cdot \Gamma \left(\frac{\delta+t+1}{2} - \frac{1}{2} x_{t} \right) \cdot \delta!}{ \Gamma(\frac{\delta+1}{2})^2 \cdot (\delta+t)!}, 
\end{equation}
and $b_t= \frac{x_{t-1}}{\delta+t}$.
As before, the couple $(f,b_t)$ satisfies the conditions in Assumption~1.

The betting function comes directly from the proof, in order to have the terms $\epsilon_t=0$ in the third condition in Assumption~1.

We now prove a simple lower bound to the value of the potential function after $T$ rounds, using the following technical Lemma.
\begin{lemma}
Let $\delta \geq 0$. Then
\[
\frac{\delta!}{2^\delta \Gamma(\frac{\delta+1}{2})^2} \geq 
\begin{cases}
\frac{1}{\pi}, \delta=0\\
\frac{1}{\pi} \frac{\sqrt{e} \sqrt{\delta+1}}{\sqrt{\pi}}, \delta>0~.
\end{cases}
\]
\end{lemma}
\begin{proof}
\begin{align}
\frac{\delta!}{2^\delta \Gamma(\frac{\delta+1}{2})^2} 
&= \frac{\Gamma(\delta+1)}{2^\delta \Gamma(\frac{\delta+1}{2})^2} \\
&= \frac{\Gamma(\delta+1) \Gamma(\frac{\delta}{2})^2}{\pi 2^{2-\delta} \Gamma(\delta)^2} \\
&= \frac{\delta^2 \Gamma(\delta+1) \Gamma(\frac{\delta}{2}+1)^2}{\frac{\delta^2}{4} \pi 2^{2-\delta} \Gamma(1+\delta)^2} \\
&= \frac{\Gamma(\frac{\delta}{2}+1)^2}{\pi 2^{-\delta} \Gamma(1+\delta)} \\
&\geq \frac{2 e \left(\frac{\delta+1}{2 \, e}\right)^{\delta+1}}{\pi 2^{-\delta} \left(\frac{\delta+0.5}{e}\right)^{\delta+0.5}\sqrt{2 \pi}} \\
&\geq \frac{\sqrt{e} \sqrt{\delta+1}}{\pi \sqrt{\pi}} \\
\end{align}
where we used the property $x \Gamma(x) =\Gamma(x+1)$ in the first and third equalities, the doubling formula for the Gamma function in the second inequality, Theorem 1.5 from \cite{Batir08} in the first inequality, and $(x+1)^{x+0.5} (x+0.5)^{-x-0.5}\geq \sqrt{2}$.
\end{proof}


Hence, using the above betting strategy, we have exactly the same guarantee for $\delta=0$, while for $\delta>0$ we have
the following guarantee
\[
\Wealth_T = \epsilon_0 + \sum_{t=1}^T w_t g_t \geq \epsilon_0 \exp\left( (T+\delta) \, \DKL\left(\frac{1}{2}+\frac{\|\theta_T\|}{2(T+\delta)}\middle\|\frac{1}{2}\right) + \frac{1}{2}\ln \frac{\delta+1}{\delta+T} - 3\right) 
\]

If we know beforehand the lenght of the game, $T$, we can set $\delta$ to a fraction of $T$ to trade-off some wealth for the logarithmic factor in $T$. For example, setting $\delta=T/2$ and using Lemma~\ref{lemma:gamma_apprx}, we get
\[
\Wealth_T = \epsilon_0 + \sum_{t=1}^T w_t g_t \geq \epsilon_0 \exp\left( \frac{\|\theta_T\|}{3T} -4\right) \;.
\]
Compared to Theorem~\ref{}, we are losing on the leading constant in the denominator in the exponent. However, as altready said at the beginning of this Section, the leading term does not play a major role in our reductions.
An interesting observation is that this betting strategy is similar to the fractional Kelly one's~\cite{}. There, a constant fraction of the optimal betting is used. Here, we show that knowning the lenght of the game allows a more natural strategy, that bets more aggressively approaching the end of the game.

Using this algorithm in Theorem~\ref{theo:expert_reduction}, we obtain a very clean quantile guarantee.
\begin{cor}
\label{cor:kt_expert}
Fix $T>0$. Let $l_t$ an arbitrary sequence of loss vectors in $[0,1]^d$. Using the notation the Normal Potential as a base learner, where $\epsilon_0=1$, the following holds
\[
\sum_{t=1}^T \langle p_t, l_t\rangle -\sum_{t=1}^T \langle u , l_t\rangle 
\leq \sqrt{3 T \left(\DKL(u||q) + \ln 4 \right)} \; .
\]
\end{cor}
Other choices of $\delta$ allow different trade-offs between the leading multiplicative term of the bound and the logarithmic constant inside the square root.

Now, using a standard doubling-trick argument, see for example~\citet{Shalev-Shwartz12}[Section 2.3.1], we can have an algorithm that works without requiring the prior knowledge of the number of rounds with a slightly worst leading constant.
\begin{cor}
\label{cor:kt_expert_no_t}
Let $l_t$ an arbitrary sequence of loss vectors in $[0,1]^d$. Using the notation the Normal Potential as a base learner, where $\epsilon_0=1$, the following holds for any $T>0$.
\[
\sum_{t=1}^T \langle p_t, l_t\rangle -\sum_{t=1}^T \langle u , l_t\rangle 
\leq \frac{\sqrt{2}}{\sqrt{2}-1}\sqrt{3 T \left(\DKL(u||q) + \ln 4 \right)} \; .
\]
\end{cor}
The above one is the first quantile bound for expert that holds uniformly over time and does not contain $\ln \ln T$ terms.