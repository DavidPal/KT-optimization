\documentclass{article}

\usepackage{fullpage,amsthm,amsmath,amssymb}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\Exp}{\mathbf{E}}
\DeclareMathOperator{\Regret}{Regret}
\DeclareMathOperator{\Wealth}{Wealth}
\newcommand{\R}{\mathbb{R}}
\newcommand{\indicator}{\mathbf{1}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

\begin{document}

\title{Data Compression and Linear Prediction}
\author{Francesco Orabona \and D\'avid P\'al}

\maketitle

\begin{abstract}
Starting from Krichevsky-Trofimov estimator for estimating
the bias of a coin, we derive an algorithm for online linear
optimization over any Hilbert space.
\end{abstract}

\section{Introduction}

Krichevsky-Trofimov (KT) estimator is a classical estimator of bias of coin.
Given $T$ outcomes of a coin flip $q_1, q_2, \dots, q_T \in \{0,1\}$ where $1$
denotes heads and $0$ tails, KT estimator of coin's probability of heads is
$$
\frac{\frac{1}{2} + \sum_{t=1}^T q_t}{T + 1} \; .
$$
This estimator has many interesting properties. For us, the most crucial one is
that it can be used in online data compression and satisfies a bound on the
number of bits used.

We show that KT-estimator can be used to derive an algorithm for online linear
optimization over a Hilbert space and data compression bound can be used derive
a regret bound for the online linear optimization problem.

First, in section~\ref{section:online-data-compression}, we recap the online
data compression problem and show a bound on number of bits used by the KT
estimator.  Second, in section~\ref{section:log-loss}, we generalize the online
data compression problem to an online prediction with log loss and we show that
a obvious generalization of the KT estimator yields and algorithm with the same
bound. Finally, in section~\ref{section:linear-prediction}, we explain the
connection with linear prediction problem.

\section{Online Data Compression}
\label{section:online-data-compression}

Consider an online data compression problem where we predict a stream of bits;
in each round we predict the next bit based on the previous bits.  More
formally, in each round $t=1,2,\dots$, we predict probability $p_t \in [0,1]$
that the next bit equals one, and then the next bit $q_t \in \{0, 1\}$.
Our prediction $p_t$ is scored according to log-loss:
$$
\ell(p_t, q_t) = q_t \ln\left( \frac{1}{p_t}\right) + (1-q_t) \ln  \left( \frac{1}{1 - p_t} \right) \; .
$$
In information theoretic terms, $\ell(p_t, q_t)$ measures the number of bits
needed to encode $q_t$ if we use encoding that uses $\ln(\frac{1}{p_t})$ bits
to encode $+1$ and $\ln(\frac{1}{1 - p_t})$ bits to encode $0$.

After $T$ rounds, the algorithm incurs loss $\sum_{t=1}^T \ell(p_t, q_t)$.
We compare this loss with an offline baseline that in round $1,2,\dots,T$
predicts the same prediction
$$
p^* = \argmin_{p \in [0,1]} \sum_{t=1}^T \ell(p, q_t) \; .
$$
Note that $p^*$ can calculate only with the knowledge of all the outcomes $q_1,
q_2, \dots, q_T$. Hence the name offline.

Let
$$
a_T = \sum_{t=1}^T q_t \qquad \text{and} \qquad b_T = \sum_{t=1}^T (1 - q_t) = T - a_T \; .
$$
We have
\begin{align*}
p^*
= \argmin_{p \in [0,1]} \ a_T \cdot  \ln \left( \frac{1}{p} \right) + b_T \cdot \ln \left( \frac{1}{1-p} \right)
= \argmin_{p \in [0,1]} \ - a_T \cdot  \ln p \ - \  b_T \cdot \ln (1-p)
\end{align*}
Defining $f(p) = - a_T \cdot  \ln p \ - \  b_T \cdot \ln(1-p)$, we can find maximum of
finding point the derivative of $f(p)$ is zero. The derivative of $f(p)$ is
$$
f'(p) = - \frac{a_T}{p} + \frac{b_T}{1-p} \; .
$$
The equation $f'(p) = 0$ has only one solution
$$
p^* = \frac{a_T}{a_T + b_T} = \frac{a_T}{T} = \frac{\sum_{t=1}^T q_t}{T} \; .
$$
Note that $p^*$ differs from the KT estimate $p_T$.

The type of result that we are interested is an upper bound on
difference between the loss of the algorithm and the loss of the baseline
$$
\sum_{t=1}^T \ell(p_t, q_t) - \sum_{t=1}^T \ell(p^*, q_t) \; ,
$$
which can be viewed as the cost for not knowing the fraction of bits set to $1$.

\subsection{KT estimator}

We consider an algorithm that in round $t$ predicts according to KT estimator
$$
p_t = \frac{\frac{1}{2} + \sum_{t=1}^{t-1} q_i}{t} = \frac{\frac{1}{2} + a_{t-1}}{t} \; .
$$
We show the following equality of loss of the algorithm:

\begin{lemma}
For any sequence $q_1, q_2, \dots, q_T \in \{0,1\}$, the log-loss of KT predictions is
$$
\sum_{t=1}^T \ell(p_t, q_t) =  - \ln \left( \frac{\Gamma(a_T + 1/2) \cdot \Gamma(b_T + 1/2)}{\pi \cdot T!} \right)
$$
where $a_T = \sum_{t=1}^T q_t$ and $b_T = T - a_T$ and $\Gamma(x)$ is the Euler's Gamma function.
\end{lemma}

\begin{proof}
We prove the equality by induction $T$. For $T=0$ the equality is
$$
0 = - \ln \left( \frac{\Gamma(1/2) \cdot \Gamma(1/2)}{\pi \cdot 0!} \right)
$$
which holds true since $\Gamma(1/2) = \sqrt{\pi}$.
For $T \ge 1$, we use the induction hypothesis for $T-1$ and some algebraic manipulation
\begin{align*}
\sum_{t=1}^T \ell(p_t, q_t)
& = \ell(p_T, q_T) + \sum_{t=1}^{T-1} \ell(p_t, q_t) \\
& = \ell(p_T, q_T) - \ln \left( \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot (T-1)!} \right) \\
& = q_T \ln\left( \frac{1}{p_T}\right) + (1-q_T) \ln  \left( \frac{1}{1 - p_T} \right) - \ln \left( \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot (T-1)!} \right) \\
& = - q_T \ln\left( \frac{\frac{1}{2} + a_{T-1}}{T} \right) - (1-q_T) \ln\left( \frac{\frac{1}{2} + b_{T-1}}{T} \right) - \ln \left( \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot (T-1)!} \right) \\
& = - \ln\left( \left( \frac{\frac{1}{2} + a_{T-1}}{T} \right)^{q_T} \left( \frac{\frac{1}{2} + b_{T-1}}{T} \right)^{1-q_T} \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot (T-1)!} \right) \\
& = - \ln\left( \left( \frac{1}{2} + a_{T-1} \right)^{q_T} \left( \frac{1}{2} + b_{T-1} \right)^{1-q_T} \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot T!}  \right) \; .
\end{align*}
It remains to prove that expression inside logarithm equals
$$
\frac{\Gamma(a_{T} + 1/2) \cdot \Gamma(b_T + 1/2)}{\pi \cdot T!}
$$
We consider two cases. If $q_T = 1$ then
\begin{align*}
& \left( \frac{1}{2} + a_{T-1} \right)^{q_T} \left( \frac{1}{2} + b_{T-1} \right)^{1-q_T} \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot T!} \\
& = \left( \frac{1}{2} + a_{T-1} \right) \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot T!} \\
& = \frac{\Gamma(a_{T-1} + 3/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot T!} \\
& = \frac{\Gamma(a_{T} + 1/2) \cdot \Gamma(b_T + 1/2)}{\pi \cdot T!} \; ,
\end{align*}
where we have used that $\Gamma(x+1) = x \Gamma(x)$ for any real $x > 0$ and that $a_T = a_{T-1} + q_T = a_{T-1} + 1$ and $b_T = b_{T-1} + (1-q_T) = b_{T-1}$.
Similarly, if $q_T = 0$ then
\begin{align*}
& \left( \frac{1}{2} + a_{T-1} \right)^{q_T} \left( \frac{1}{2} + b_{T-1} \right)^{1-q_T} \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot T!} \\
& = \left( \frac{1}{2} + b_{T-1} \right) \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 1/2)}{\pi \cdot T!} \\
& = \frac{\Gamma(a_{T-1} + 1/2) \cdot \Gamma(b_{T-1} + 3/2)}{\pi \cdot T!} \\
& = \frac{\Gamma(a_T + 1/2) \cdot \Gamma(b_T + 3/2)}{\pi \cdot T!} \; ,
\end{align*}
where we have used that $\Gamma(x+1) = x \Gamma(x)$ for any real $x > 0$ and that $a_T = a_{T-1} + q_T = a_{T-1}$ and $b_T = b_{T-1} + (1-q_T) = b_{T-1} + 1$.
\end{proof}

\begin{lemma}
For any non-negative integers $a, b,T$ such that $a + b = T$ we have
$$
\frac{\Gamma(a + 1/2) \cdot \Gamma(b + 1/2)}{\pi \cdot T!} \ge \frac{1}{2\sqrt{T}} \left( \frac{a}{T} \right)^a \left( \frac{b}{T} \right)^b \; .
$$
\end{lemma}

Combining the two lemmas we get
\begin{align*}
\sum_{t=1}^T \ell(p_t, q_t)
& \le - \ln \left( \frac{1}{2\sqrt{T}} \left( \frac{a_T}{T} \right)^{a_T} \left( \frac{b_T}{T} \right)^{b_T} \right) \\
& = \ln(2) + \frac{1}{2} \ln(T) - a_T \ln (p^*) - b_T \ln (1-p^*) \\
& = \ln(2) + \frac{1}{2} \ln(T) + \sum_{t=1}^T \ell(p^*, q_t) \; .
\end{align*}

\section{Online Log Loss Game}

We consider a generalization of the data compression game where $q_t$ is not restricted
the set $\{0,1\}$ but it is allowed to be any real number in the interval $[0,1]$.
If in round $t$ we predict $p_t \in [0,1]$ and then receive $q_t \in [0,1]$ the loss is
$$
\ell(p_t, q_t) = q_t \ln\left( \frac{1}{p_t}\right) + (1-q_t) \ln  \left( \frac{1}{1 - p_t} \right) \; .
$$

The formulas for $a_T, b_T$ and $p^*$ remain exactly the same as before
\begin{align*}
a_T & = \sum_{t=1}^T q_t \; , \\
b_T & = \sum_{t=1}^T (1 - q_t) = T - a_T \; , \\
p^* & =  \argmin_{p \in [0,1]} \sum_{t=1}^T \ell(p, q_t) = \frac{a_T}{a_T + b_T} = \frac{a_T}{T} = \frac{\sum_{t=1}^T q_t}{T} \; .
\end{align*}

The KT estimator is generalized in the obvious way
$$
p_t = \frac{\frac{1}{2} + \sum_{t=1}^{t-1} q_i}{t} = \frac{\frac{1}{2} + a_{t-1}}{t} \; .
$$

\subsection{Bound on loss of the KT Estimator}

Let $\widetilde q_1, \widetilde q_2, \dots, \widetilde q_T$ independent
Bernoulli variables with parameters $q_1, q_2, \dots, q_T$ respectively.
Let
\begin{align*}
\widetilde a_t & = \sum_{i=1}^t \widetilde q_i  \; , \\
\widetilde b_t & = t - \widetilde a_t \; , \\
\widetilde p_t & = \frac{\frac{1}{2} + \sum_{i=1}^{t-1} \widetilde q_i}{t} = \frac{\frac{1}{2} + \widetilde a_{t-1}}{t} \; , \\
\widehat p & = \frac{\widetilde a_T}{T} = \frac{\widetilde a_T}{\widetilde a_T + \widetilde b_T} \; . \\
\end{align*}
Clearly,
\begin{align*}
q_i & = \Exp[\widetilde q_i] \; , \\
a_t & = \Exp[\widetilde a_t] \; , \\
b_t & = \Exp[\widetilde b_t] \; , \\
p_t & = \Exp[\widetilde p_t] \; , \\
p^* & = \Exp[\widehat p] \; .
\end{align*}

Since $\ell(p,q)$ is linear in $q$ and convex in $p$, we have
\begin{align*}
\sum_{t=1}^T \ell(p_t, q_t)
& = \sum_{t=1}^T \ell( \Exp[ \widetilde p_t], \Exp[\widetilde q_t]) \\
& = \Exp\left[ \sum_{t=1}^T \ell( \Exp[ \widetilde p_t], \widetilde q_t) \right] \\
& \le \Exp\left[ \sum_{t=1}^T \ell( \widetilde p_t, \widetilde q_t) \right] \\
& \le - \Exp\left[ \ln \left\{ \frac{1}{2\sqrt{T}} \left( \frac{\widetilde a_T}{T} \right)^{\widetilde a_T} \left( \frac{\widetilde b_T}{T} \right)^{\widetilde b_T} \right\} \right] \\
& = \ln(2) + \frac{1}{2} \ln(T) + \Exp \left[ - \widetilde a_T \ln \left( \frac{\widetilde a_T}{T} \right) - \widetilde b_T \ln \left( \frac{\widetilde b_T}{T} \right) \right] \\
& = \ln(2) + \frac{1}{2} \ln(T) + T \cdot \Exp \left[ H(\widehat p) \right] \\
& \le \ln(2) + \frac{1}{2} \ln(T) + T \cdot H(\Exp[\widehat p]) \\
& = \ln(2) + \frac{1}{2} \ln(T) + T \cdot H(p^*)
\end{align*}
where $H(x) = - x \ln(x) - (1-x) \ln (1-x)$ is the binary entropy function.

\section{More general game}

Consider an online game where each round we predict $w_t \in \R$
and the adversary chooses $g_t \in [-1,1]$. The algorithm tries to maximize
its cumulative gain $\sum_{t=1}^T w_t x_t$. The goal of algorithm
is to have small regret after $T$ rounds w.r.t. competitor $u \in \R$:
$$
\Regret_T(u) = \sum_{t=1}^t g_t u - \sum_{t=1}^T w_t x_t \; .
$$

We can view algorithms of certain form, which we call betting algorithms.  A
betting algorithm starts with $\Wealth_0 = 1$ dollars.
In every round, it chooses a ``fraction'' $\beta_t \in [-1,1]$ of its current
wealth to bet. The algorithm predicts
$$
w_t = \beta_t \cdot \Wealth_{t-1}
$$
where $\Wealth_t = 1 + \sum_{i=1}^t g_t w_t$. After making its prediction,
the algorithm's wealth is
$$
\Wealth_t = g_t w_t + \Wealth_{t-1} = g_t \beta_t \Wealth_{t-1} + \Wealth_t = (1 + g_t\beta_t) \Wealth_{t-1} \; .
$$
Hence
$$
\Wealth_T = \prod_{t=1}^T (1 + g_t\beta_t) \; .
$$

\subsection{KT estimator for $\beta_t$}

We use KT estimator to define predictions $\beta_t$. Let
\begin{align*}
q_t & = \frac{1 + g_t}{2} \\
a_T & = \sum_{t=1}^T q_t \; , \\
b_T & = \sum_{t=1}^T (1 - q_t) = T - a_T \; , \\
p^* & =  \argmin_{p \in [0,1]} \sum_{t=1}^T \ell(p, q_t) = \frac{a_T}{a_T + b_T} = \frac{a_T}{T} = \frac{\sum_{t=1}^T q_t}{T} \; .
\end{align*}
We use the corresponding KT estimator
$$
p_t = \frac{\frac{1}{2} + \sum_{t=1}^{t-1} q_i}{t} = \frac{\frac{1}{2} + a_{t-1}}{t}
$$
to define $\beta_t$ as
$$
\beta_t = 2p_t - 1 \; .
$$
The following inequality will be useful
$$
\ln\left(1 + \beta g \right) \ge \left( \frac{1+g}{2} \right) \ln \left(1 + \beta\right) + \left( \frac{1-g}{2} \right) \ln \left(1 - \beta \right)
\qquad \text{for $g \in [-1,1]$ and $\beta \in (-1,1)$}.
$$

We lower bound logarithm of the wealth as follows
\begin{align*}
\ln \Wealth_T
& = \ln \prod_{t=1}^T (1 + g_t\beta_t) \\
& =  \sum_{t=1}^T \ln (1 + g_t\beta_t) \\
& \ge  \sum_{t=1}^T \left( \frac{1+g_t}{2} \right) \ln \left(1 + \beta_t\right) + \left( \frac{1-g_t}{2} \right) \ln \left(1 - \beta_t \right) \\
& =  \sum_{t=1}^T \left( \frac{1+g_t}{2} \right) \ln \left(2p_t \right) + \left( \frac{1-g_t}{2} \right) \ln \left(2 (1 - p_t) \right) \\
& =  T \ln(2) + \sum_{t=1}^T \left( \frac{1+g_t}{2} \right) \ln (p_t) + \left( \frac{1-g_t}{2} \right) \ln (1 - p_t) \\
& =  T \ln(2) - \sum_{t=1}^T \ell(p_t, q_t) \\
& \ge  T \ln(2) - \ln(2) - \frac{1}{2} \ln(T) - T \cdot H(p^*) \\
& =  - \ln(2) - \frac{1}{2} \ln(T) - T \cdot (H(p^*) + \ln(1/2)) \\
& =  - \ln(2) - \frac{1}{2} \ln(T) + T \cdot D\left(p^*, 1/2 \right)
\end{align*}
where $D(u,v) = u \ln(u/v) + (1-v) \ln((1-u)/(1-v))$ is the Kullback-Leibler divergence
between Bernoulli random variables with parameters $u,v$.

\end{document}
